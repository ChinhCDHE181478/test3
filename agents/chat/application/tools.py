from datetime import datetime
from typing import Literal, Annotated, Optional

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import SystemMessage
from langchain_core.prompts import MessagesPlaceholder
from langgraph.prebuilt import InjectedState
from langchain_core.output_parsers import PydanticOutputParser
from langchain_tavily import TavilySearch
from langchain_core.runnables import RunnableConfig
from langchain_core.tools import tool, InjectedToolCallId
from langgraph.types import Command
from langchain_core.messages import ToolMessage
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.tools import StructuredTool

from shared.tools.search_places import SearchPlacesTool
from shared.infrastructure.config.settings import settings
from shared.infrastructure.llm import extract_llm
from shared.models import Place, Plan


tavily_instance = TavilySearch(
    max_results=5,
    topic="general",
    tavily_api_key=settings.TAVILY_API_KEY,
)

@tool("tavily_search")
def search_tool(query: str, config: RunnableConfig = None):
    """A search engine optimized for comprehensive, accurate, and trusted results. Useful for when you need to answer questions about current events."""
    return tavily_instance.invoke(query, config=config)

search_places_tool = SearchPlacesTool(api_key=settings.SERPAPI_API_KEY)

# helper to remove assistant messages with pending tool_calls
def _filter_conversation_messages(messages: list[BaseMessage]) -> list[BaseMessage]:
    filtered: list[BaseMessage] = []
    for m in messages:
        if isinstance(m, HumanMessage):
            filtered.append(m)
        elif isinstance(m, AIMessage) and not m.tool_calls and m.content:
            filtered.append(m)
    return filtered

@tool("search_for_places", parse_docstring=True)
async def search_for_places(
    queries: list[str],
    language: Optional[str] = None,
    state: Annotated[dict, InjectedState] = None,
    config: RunnableConfig = None,
) -> list[Place]:
    """
    Search for places based on queries, language, returns a list of places including their name, address, and coordinates.

    Args:
        queries (list[str]): A list of queries to search for places.
        language (str, optional): The language to search in.

    Returns:
        list[Place]: A list of places.
    """
    language = language or (state.get("language") if state else "vi")
    if config is None:
        from loguru import logger
        logger.warning("search_for_places: config is None")
    return await search_places_tool.search_for_places(queries, language)

search_for_places.name = "search_for_places"
search_for_places.description = "Search for places based on queries, language, returns a list of places including their name, address, and coordinates."


@tool("plan_itinerary")
async def plan_itinerary(
    language: Optional[str] = None,
    state: Annotated[dict, InjectedState] = None,
    tool_call_id: Annotated[str, InjectedToolCallId] = None,
    config: RunnableConfig = None,
) -> Command[Literal["plan_agent", "chat_node"]]:
    """
    Extract the plan details from summary and messages then transfer to Plan Agent to create an itinerary.
    """
    parser = PydanticOutputParser(pydantic_object=Plan)

    system_prompt = """Extract a travel plan from the user's conversation.
**PAY ATTENTION** to budget range, user preferences and time range of the trip.
{format_instructions}
Return ONLY a valid JSON object. Do not wrap in code fences or tags.
\n**DO NOT** add any explanation or additional text.
\nResponse in {language} language.
\nAlways refer to current year if the user doesn't specify the year. current datetime: {current_datetime}
\nSummary of the conversation so far (if any):\n{summary}"""
    language = language or state.get("language", "vi")
    system_prompt = system_prompt.format(
        format_instructions=parser.get_format_instructions(),
        language=language,
        summary=state.get("summary", ""),
        current_datetime=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessage(content=system_prompt),
            MessagesPlaceholder(variable_name="messages"),
        ]
    )

    chain = prompt | extract_llm | parser

    conv_messages = _filter_conversation_messages(state["messages"])
    if config is None:
        from loguru import logger
        logger.warning("plan_itinerary: config is None, command might fail")
    plan: Plan = await chain.ainvoke({"messages": conv_messages}, config=config)

    return Command(
        goto="plan_agent",
        update={
            "plan": plan,
            "language": language,
            "messages": state["messages"]
            + [
                ToolMessage(
                    content="Transfer to Plan Agent",
                    tool_call_id=tool_call_id,
                    name="plan_itinerary",
                )
            ],
        },
        graph=Command.PARENT,
    )

plan_itinerary.name = "plan_itinerary"
plan_itinerary.description = "Extract the plan details from summary and messages then transfer to Plan Agent to create an itinerary."
